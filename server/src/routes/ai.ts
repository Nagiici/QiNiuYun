import express from 'express';
import axios from 'axios';
import FormData from 'form-data';
import { DatabaseService } from '../database';

export const aiRouter = express.Router();

// AIæœåŠ¡é…ç½®
const AI_CONFIG = {
  // ä½¿ç”¨å…è´¹çš„Ollamaæœ¬åœ°æœåŠ¡ (å¦‚æœå®‰è£…äº†)
  OLLAMA_URL: process.env.OLLAMA_URL || 'http://localhost:11434',

  // å…è´¹APIé€‰é¡¹ (éœ€è¦API keyï¼Œä½†æä¾›å…è´¹é¢åº¦)
  GROQ_API_URL: 'https://api.groq.com/openai/v1/chat/completions',
  GROQ_API_KEY: process.env.GROQ_API_KEY,

  COHERE_API_URL: 'https://api.cohere.ai/v1/generate',
  COHERE_API_KEY: process.env.COHERE_API_KEY,

  OPENAI_API_URL: process.env.OPENAI_API_URL || 'https://api.openai.com/v1/chat/completions',
  OPENAI_API_KEY: process.env.OPENAI_API_KEY,

  // Anthropic Claude API
  ANTHROPIC_API_URL: 'https://api.anthropic.com/v1/messages',
  ANTHROPIC_API_KEY: process.env.ANTHROPIC_API_KEY,
};

// AIå¯¹è¯ç”Ÿæˆ
aiRouter.post('/chat', async (req, res) => {
  try {
    const { message, character_id, session_id, character_data } = req.body;

    if (!message || !character_id) {
      return res.status(400).json({ error: 'Message and character_id are required' });
    }

    let character;

    // å¦‚æœcharacter_idæ˜¯999ä¸”æä¾›äº†character_dataï¼Œä½¿ç”¨ä¸´æ—¶è§’è‰²æ•°æ®ï¼ˆç”¨äºæµ‹è¯•é¢„è§ˆï¼‰
    if (character_id === 999 && character_data) {
      character = character_data;
    } else {
      // è·å–æ•°æ®åº“ä¸­çš„è§’è‰²ä¿¡æ¯
      character = await DatabaseService.getCharacterById(character_id);
      if (!character) {
        return res.status(404).json({ error: 'Character not found' });
      }
    }

    // æ„å»ºAIæç¤ºè¯ï¼ˆåŒ…å«ä¼šè¯IDä»¥æ”¯æŒè®°å¿†åŠŸèƒ½ï¼‰
    const aiResponse = await generateAIResponse(message, character, session_id);

    // åªæœ‰æ­£å¸¸èŠå¤©æ—¶æ‰ä¿å­˜æ¶ˆæ¯ï¼ˆæµ‹è¯•é¢„è§ˆæ—¶ä¸ä¿å­˜ï¼‰
    if (session_id && character_id !== 999) {
      await DatabaseService.addChatMessage(session_id, 'user', message, 'text');
      await DatabaseService.addChatMessage(session_id, 'ai', aiResponse, 'text');
    }

    res.json({
      response: aiResponse,
      character_name: character.name,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    console.error('Error generating AI response:', error);
    res.status(500).json({ error: 'Failed to generate AI response' });
  }
});

// æƒ…æ„Ÿåˆ†æ
aiRouter.post('/emotion', async (req, res) => {
  try {
    const { message } = req.body;

    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }

    const emotionAnalysis = enhancedEmotionAnalysis(message);

    res.json({
      emotion: emotionAnalysis.emotion,
      intensity: emotionAnalysis.intensity,
      keywords: emotionAnalysis.keywords
    });
  } catch (error) {
    console.error('Error analyzing emotion:', error);
    res.status(500).json({ error: 'Failed to analyze emotion' });
  }
});

// ç”ŸæˆAIå›å¤
async function generateAIResponse(userMessage: string, character: any, sessionId?: string): Promise<string> {
  try {
    // è§£æè§’è‰²æ•°æ®
    let personalityData, examples;
    try {
      personalityData = JSON.parse(character.personality_data || '{}');
      examples = JSON.parse(character.examples || '[]');
    } catch {
      personalityData = {};
      examples = [];
    }

    // è·å–å¯¹è¯å†å²ä½œä¸ºè®°å¿†ä¸Šä¸‹æ–‡
    let conversationHistory = '';
    if (sessionId) {
      const recentMessages = await getRecentConversationHistory(sessionId, 5); // è·å–æœ€è¿‘5è½®å¯¹è¯
      conversationHistory = buildConversationContext(recentMessages);
    }

    // æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«è®°å¿†ï¼‰
    const systemPrompt = buildEnhancedSystemPrompt(character, personalityData, examples, conversationHistory);

    // è·å–å½“å‰AIé…ç½®
    const aiConfiguration = await DatabaseService.getAiConfiguration();
    const currentProvider = aiConfiguration?.currentProvider || 'groq';
    const temperature = aiConfiguration?.temperature || 0.7;
    const providers = aiConfiguration?.providers || {};

    // æ ¹æ®é…ç½®çš„å½“å‰æä¾›å•†å°è¯•AIæœåŠ¡
    if (currentProvider !== 'fallback') {
      try {
        let response: string | null = null;

        switch (currentProvider) {
          case 'groq':
            if (providers.groq?.apiKey) {
              console.log('Using configured Groq API...');
              response = await tryGroqAPIWithConfig(systemPrompt, userMessage, providers.groq, temperature);
            }
            break;
          case 'openai':
            if (providers.openai?.apiKey) {
              console.log('Using configured OpenAI API...');
              response = await tryOpenAIAPIWithConfig(systemPrompt, userMessage, providers.openai, temperature);
            }
            break;
          case 'cohere':
            if (providers.cohere?.apiKey) {
              console.log('Using configured Cohere API...');
              response = await tryCohereAPIWithConfig(systemPrompt, userMessage, providers.cohere, temperature);
            }
            break;
          case 'anthropic':
            if (providers.anthropic?.apiKey) {
              console.log('Using configured Anthropic API...');
              response = await tryAnthropicAPIWithConfig(systemPrompt, userMessage, providers.anthropic, temperature);
            }
            break;
          case 'ollama':
            if (providers.ollama?.baseURL) {
              console.log('Using configured Ollama API...');
              response = await tryOllamaAPIWithConfig(systemPrompt, userMessage, providers.ollama);
            }
            break;
        }

        if (response) {
          console.log(`âœ… ${currentProvider} API successful`);
          return response;
        } else {
          console.log(`âŒ ${currentProvider} API failed or not configured`);
        }
      } catch (error: any) {
        console.log(`âŒ ${currentProvider} API failed:`, error.message);
      }
    }

    // å¦‚æœé…ç½®çš„æä¾›å•†å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„å…¶ä»–æä¾›å•†ä½œä¸ºåå¤‡
    console.log('Trying fallback providers from environment variables...');
    const fallbackServices = [
      { name: 'Groq', fn: () => tryGroqAPI(systemPrompt, userMessage) },
      { name: 'OpenAI', fn: () => tryOpenAIAPI(systemPrompt, userMessage) },
      { name: 'Cohere', fn: () => tryCohereAPI(systemPrompt, userMessage) },
      { name: 'Anthropic', fn: () => tryAnthropicAPI(systemPrompt, userMessage) },
      { name: 'Ollama', fn: () => tryOllamaAPI(systemPrompt, userMessage) },
    ];

    // ä¾æ¬¡å°è¯•å¯ç”¨çš„AIæœåŠ¡
    for (const service of fallbackServices) {
      try {
        console.log(`Trying ${service.name} API (fallback)...`);
        const response = await service.fn();
        if (response) {
          console.log(`âœ… ${service.name} API successful (fallback)`);
          return response;
        }
      } catch (error: any) {
        console.log(`âŒ ${service.name} API failed (fallback):`, error.message);
        continue;
      }
    }

    console.log('All AI services failed, using rule-based fallback...');
    return generateRuleBasedResponse(userMessage, character, personalityData, examples);
  } catch (error) {
    console.error('Error in generateAIResponse:', error);
    return generateRuleBasedResponse(userMessage, character, { energy: 50, friendliness: 70 }, []);
  }
}

// æ„å»ºç³»ç»Ÿæç¤ºè¯
function buildSystemPrompt(character: any, personalityData: any, examples: any[]): string {
  let prompt = `ä½ æ˜¯${character.name}ã€‚${character.description}\n\n`;

  // æ²‰æµ¸å¼ä¸–ç•Œè®¾å®š
  if (character.story_world) {
    prompt += `=== ä¸–ç•Œç¯å¢ƒ ===\nä½ æ‰€å¤„çš„ä¸–ç•Œï¼š${character.story_world}\n\n`;
  }

  if (character.character_background) {
    prompt += `=== è§’è‰²èƒŒæ™¯ ===\n${character.character_background}\n\n`;
  }

  if (character.story_background) {
    prompt += `èƒŒæ™¯æ•…äº‹ï¼š${character.story_background}\n\n`;
  }

  // å½“å‰ä»»åŠ¡å’Œæƒ…å¢ƒ
  if (character.has_mission && character.current_mission) {
    prompt += `=== å½“å‰ä»»åŠ¡ ===\n${character.current_mission}\n\n`;
  }

  if (character.current_mood) {
    const moodMap = {
      happy: 'å¼€å¿ƒæ„‰æ‚¦', sad: 'æ‚²ä¼¤æ²®ä¸§', angry: 'æ„¤æ€’ç”Ÿæ°”', excited: 'å…´å¥‹æ¿€åŠ¨',
      nervous: 'ç´§å¼ ä¸å®‰', calm: 'å¹³é™å†·é™', confused: 'å›°æƒ‘è¿·èŒ«', determined: 'åšå®šæœæ–­'
    };
    prompt += `=== æƒ…ç»ªçŠ¶æ€ ===\nå½“å‰æƒ…ç»ªï¼š${moodMap[character.current_mood as keyof typeof moodMap] || character.current_mood}\n\n`;
  }

  if (character.time_setting) {
    const timeMap = {
      morning: 'æ¸…æ™¨', noon: 'æ­£åˆ', afternoon: 'ä¸‹åˆ',
      evening: 'å‚æ™š', night: 'å¤œæ™š', midnight: 'æ·±å¤œ'
    };
    prompt += `=== æ—¶é—´è®¾å®š ===\nå½“å‰æ—¶é—´ï¼š${timeMap[character.time_setting as keyof typeof timeMap] || character.time_setting}\n\n`;
  }

  if (character.custom_instructions) {
    prompt += `ç‰¹æ®ŠæŒ‡ä»¤ï¼š${character.custom_instructions}\n\n`;
  }

  // æ·»åŠ æ€§æ ¼ç‰¹å¾
  if (personalityData && Object.keys(personalityData).length > 0) {
    prompt += `æ€§æ ¼ç‰¹å¾ï¼š\n`;
    if (personalityData.energy > 70) prompt += `- æ´»æ³¼å¼€æœ—ï¼Œå……æ»¡æ´»åŠ›\n`;
    else if (personalityData.energy < 30) prompt += `- æ²‰ç¨³å†·é™ï¼Œæ·±æ€ç†Ÿè™‘\n`;

    if (personalityData.friendliness > 70) prompt += `- å‹å–„çƒ­æƒ…ï¼Œå®¹æ˜“ç›¸å¤„\n`;
    else if (personalityData.friendliness < 30) prompt += `- è¾ƒä¸ºå†·æ·¡ï¼Œä¿æŒè·ç¦»\n`;

    if (personalityData.humor > 70) prompt += `- å¹½é»˜é£è¶£ï¼Œå–„äºè°ƒèŠ‚æ°”æ°›\n`;
    else if (personalityData.humor < 30) prompt += `- ä¸¥è‚ƒè®¤çœŸï¼Œå¾ˆå°‘å¼€ç©ç¬‘\n`;

    if (personalityData.professionalism > 70) prompt += `- ä¸“ä¸šä¸¥è°¨ï¼Œæ³¨é‡ç»†èŠ‚\n`;
    if (personalityData.creativity > 70) prompt += `- å¯Œæœ‰åˆ›æ„ï¼Œæ€ç»´æ´»è·ƒ\n`;
    if (personalityData.empathy > 70) prompt += `- å–„è§£äººæ„ï¼Œå…³å¿ƒä»–äººæ„Ÿå—\n`;

    prompt += `\n`;
  }

  // æ·»åŠ å¯¹è¯ç¤ºä¾‹
  if (examples && examples.length > 0) {
    prompt += `å¯¹è¯ç¤ºä¾‹ï¼š\n`;
    examples.forEach((example: any) => {
      prompt += `ç”¨æˆ·ï¼š${example.input}\nä½ ï¼š${example.output}\n\n`;
    });
  }

  prompt += `è¯·ä»¥${character.name}çš„èº«ä»½å›å¤ï¼Œä¿æŒè§’è‰²çš„æ€§æ ¼ç‰¹å¾å’Œè¯´è¯é£æ ¼ã€‚å›å¤åº”è¯¥è‡ªç„¶ã€ç”ŸåŠ¨ï¼Œç¬¦åˆè§’è‰²è®¾å®šã€‚`;

  return prompt;
}

// åŸºäºè§„åˆ™çš„å›å¤ç”Ÿæˆï¼ˆå½“AIæœåŠ¡ä¸å¯ç”¨æ—¶çš„åå¤‡æ–¹æ¡ˆï¼‰
function generateRuleBasedResponse(userMessage: string, character: any, personalityData: any, examples: any[]): string {
  const name = character.name;
  let response = '';

  // æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„ç¤ºä¾‹
  if (examples && examples.length > 0) {
    const matchingExample = examples.find((example: any) =>
      userMessage.toLowerCase().includes(example.input.toLowerCase()) ||
      example.input.toLowerCase().includes(userMessage.toLowerCase())
    );

    if (matchingExample) {
      return matchingExample.output;
    }
  }

  // åŸºäºæ€§æ ¼ç”Ÿæˆä¸åŒé£æ ¼çš„å›å¤
  const isEnergetic = (personalityData.energy || 50) > 70;
  const isFriendly = (personalityData.friendliness || 50) > 70;
  const isHumorous = (personalityData.humor || 50) > 70;
  const isProfessional = (personalityData.professionalism || 50) > 70;

  // é—®å€™å›å¤
  if (userMessage.includes('ä½ å¥½') || userMessage.includes('hello') || userMessage.includes('hi')) {
    if (isFriendly && isEnergetic) {
      response = `ä½ å¥½ï¼æˆ‘æ˜¯${name}ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ`;
    } else if (isProfessional) {
      response = `æ‚¨å¥½ï¼Œæˆ‘æ˜¯${name}ã€‚æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘å¯ä»¥ä¸ºæ‚¨è§£ç­”ï¼Ÿ`;
    } else {
      response = `ä½ å¥½ï¼Œæˆ‘æ˜¯${name}ã€‚`;
    }
  }
  // è¯¢é—®èº«ä»½
  else if (userMessage.includes('ä½ æ˜¯è°') || userMessage.includes('ä»‹ç»')) {
    response = `æˆ‘æ˜¯${name}ã€‚${character.description}`;
    if (character.story_background) {
      response += ` ${character.story_background.substring(0, 100)}`;
    }
  }
  // é€šç”¨å›å¤
  else {
    const responses = [
      `å…³äºè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘è§‰å¾—å¾ˆæœ‰è¶£ã€‚`,
      `è®©æˆ‘æƒ³æƒ³ï¼Œè¿™ç¡®å®æ˜¯ä¸ªä¸é”™çš„è¯é¢˜ã€‚`,
      `ä½ æå‡ºäº†ä¸€ä¸ªå¾ˆæ£’çš„è§‚ç‚¹ã€‚`,
      `è¿™è®©æˆ‘æƒ³åˆ°äº†ä¸€äº›ç›¸å…³çš„äº‹æƒ…ã€‚`
    ];

    response = responses[Math.floor(Math.random() * responses.length)];

    if (isHumorous) {
      response += ' ğŸ˜Š';
    }
  }

  // æ ¹æ®æ€§æ ¼è°ƒæ•´è¯­æ°”
  if (isEnergetic) {
    response += ' ä½ è¿˜æƒ³äº†è§£ä»€ä¹ˆå‘¢ï¼Ÿ';
  } else if (isProfessional) {
    response += ' å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚';
  }

  return response;
}

// ç®€å•çš„æƒ…æ„Ÿåˆ†æ
function analyzeEmotion(message: string): string {
  const emotions = {
    joy: ['å¼€å¿ƒ', 'é«˜å…´', 'å¿«ä¹', 'å…´å¥‹', 'å“ˆå“ˆ', 'ğŸ˜Š', 'ğŸ˜„', 'ğŸ˜†'],
    sad: ['ä¼¤å¿ƒ', 'éš¾è¿‡', 'æ²®ä¸§', 'å¤±æœ›', 'å“­', 'ğŸ˜¢', 'ğŸ˜­', 'â˜¹ï¸'],
    angry: ['ç”Ÿæ°”', 'æ„¤æ€’', 'è®¨åŒ', 'çƒ¦', 'æ°”æ­»', 'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ’¢'],
    fear: ['å®³æ€•', 'ææƒ§', 'æ‹…å¿ƒ', 'ç„¦è™‘', 'ç´§å¼ ', 'ğŸ˜¨', 'ğŸ˜°', 'ğŸ˜±'],
    surprise: ['æƒŠè®¶', 'æ„å¤–', 'æ²¡æƒ³åˆ°', 'å“‡', 'ğŸ˜¯', 'ğŸ˜®', 'ğŸ˜²'],
    love: ['çˆ±', 'å–œæ¬¢', 'å¿ƒåŠ¨', 'â¤ï¸', 'ğŸ’•', 'ğŸ˜', 'ğŸ¥°']
  };

  for (const [emotion, keywords] of Object.entries(emotions)) {
    for (const keyword of keywords) {
      if (message.includes(keyword)) {
        return emotion;
      }
    }
  }

  return 'neutral';
}

// =============== AI Service Implementations ===============

// Groq API (Free tier available)
async function tryGroqAPI(systemPrompt: string, userMessage: string): Promise<string | null> {
  if (!AI_CONFIG.GROQ_API_KEY) {
    return null;
  }

  const response = await axios.post(AI_CONFIG.GROQ_API_URL, {
    model: 'llama3-8b-8192', // æˆ– 'mixtral-8x7b-32768'
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userMessage }
    ],
    max_tokens: 500,
    temperature: 0.7
  }, {
    headers: {
      'Authorization': `Bearer ${AI_CONFIG.GROQ_API_KEY}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.data.choices[0]?.message?.content || null;
}

// OpenAI API (Free tier available for new accounts)
async function tryOpenAIAPI(systemPrompt: string, userMessage: string): Promise<string | null> {
  if (!AI_CONFIG.OPENAI_API_KEY) {
    return null;
  }

  const response = await axios.post(AI_CONFIG.OPENAI_API_URL, {
    model: 'gpt-3.5-turbo', // æ›´ä¾¿å®œçš„é€‰æ‹©
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userMessage }
    ],
    max_tokens: 500,
    temperature: 0.7
  }, {
    headers: {
      'Authorization': `Bearer ${AI_CONFIG.OPENAI_API_KEY}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.data.choices[0]?.message?.content || null;
}

// Cohere API (Free tier available)
async function tryCohereAPI(systemPrompt: string, userMessage: string): Promise<string | null> {
  if (!AI_CONFIG.COHERE_API_KEY) {
    return null;
  }

  const prompt = `${systemPrompt}\n\nUser: ${userMessage}\nAssistant:`;

  const response = await axios.post(AI_CONFIG.COHERE_API_URL, {
    model: 'command-light', // å…è´¹æ¨¡å‹
    prompt: prompt,
    max_tokens: 500,
    temperature: 0.7,
    stop_sequences: ['User:', '\n\nUser:']
  }, {
    headers: {
      'Authorization': `Bearer ${AI_CONFIG.COHERE_API_KEY}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.data.generations[0]?.text?.trim() || null;
}

// Anthropic Claude API
async function tryAnthropicAPI(systemPrompt: string, userMessage: string): Promise<string | null> {
  if (!AI_CONFIG.ANTHROPIC_API_KEY) {
    return null;
  }

  const response = await axios.post(AI_CONFIG.ANTHROPIC_API_URL, {
    model: 'claude-3-haiku-20240307', // æœ€ä¾¿å®œçš„Claudeæ¨¡å‹
    max_tokens: 500,
    system: systemPrompt,
    messages: [
      { role: 'user', content: userMessage }
    ]
  }, {
    headers: {
      'x-api-key': AI_CONFIG.ANTHROPIC_API_KEY,
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01'
    },
    timeout: 10000
  });

  return response.data.content[0]?.text || null;
}

// Ollama Local API
async function tryOllamaAPI(systemPrompt: string, userMessage: string): Promise<string | null> {
  const response = await axios.post(`${AI_CONFIG.OLLAMA_URL}/api/generate`, {
    model: 'llama3.1:8b', // ä½¿ç”¨å¯ç”¨çš„æ¨¡å‹
    prompt: `${systemPrompt}\n\nUser: ${userMessage}\nAssistant:`,
    stream: false,
    options: {
      temperature: 0.7,
      num_ctx: 4096
    }
  }, {
    timeout: 60000, // å¢åŠ åˆ°60ç§’è¶…æ—¶
    headers: {
      'Content-Type': 'application/json; charset=utf-8'
    }
  });

  return response.data.response || null;
}

// =============== Dynamic AI Service Implementations (Using Database Config) ===============

// Groq API with dynamic config
async function tryGroqAPIWithConfig(systemPrompt: string, userMessage: string, config: any, temperature: number): Promise<string | null> {
  const response = await axios.post(AI_CONFIG.GROQ_API_URL, {
    model: config.model || 'llama-3.1-70b-versatile',
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userMessage }
    ],
    max_tokens: 500,
    temperature: temperature
  }, {
    headers: {
      'Authorization': `Bearer ${config.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.data.choices[0]?.message?.content || null;
}

// OpenAI API with dynamic config
async function tryOpenAIAPIWithConfig(systemPrompt: string, userMessage: string, config: any, temperature: number): Promise<string | null> {
  const response = await axios.post(AI_CONFIG.OPENAI_API_URL, {
    model: config.model || 'gpt-4o-mini',
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userMessage }
    ],
    max_tokens: 500,
    temperature: temperature
  }, {
    headers: {
      'Authorization': `Bearer ${config.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.data.choices[0]?.message?.content || null;
}

// Cohere API with dynamic config
async function tryCohereAPIWithConfig(systemPrompt: string, userMessage: string, config: any, temperature: number): Promise<string | null> {
  const prompt = `${systemPrompt}\n\nUser: ${userMessage}\nAssistant:`;

  const response = await axios.post(AI_CONFIG.COHERE_API_URL, {
    model: config.model || 'command-r-plus',
    prompt: prompt,
    max_tokens: 500,
    temperature: temperature,
    stop_sequences: ['User:', '\n\nUser:']
  }, {
    headers: {
      'Authorization': `Bearer ${config.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.data.generations[0]?.text?.trim() || null;
}

// Anthropic Claude API with dynamic config
async function tryAnthropicAPIWithConfig(systemPrompt: string, userMessage: string, config: any, temperature: number): Promise<string | null> {
  const response = await axios.post(AI_CONFIG.ANTHROPIC_API_URL, {
    model: config.model || 'claude-3-5-sonnet-20241022',
    max_tokens: 500,
    temperature: temperature,
    system: systemPrompt,
    messages: [
      { role: 'user', content: userMessage }
    ]
  }, {
    headers: {
      'x-api-key': config.apiKey,
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01'
    },
    timeout: 10000
  });

  return response.data.content[0]?.text || null;
}

// Ollama Local API with dynamic config
async function tryOllamaAPIWithConfig(systemPrompt: string, userMessage: string, config: any): Promise<string | null> {
  const response = await axios.post(`${config.baseURL}/api/generate`, {
    model: config.model || 'llama3.1:8b',
    prompt: `${systemPrompt}\n\nUser: ${userMessage}\nAssistant:`,
    stream: false,
    options: {
      temperature: 0.7,
      num_ctx: 4096
    }
  }, {
    timeout: 60000, // å¢åŠ åˆ°60ç§’è¶…æ—¶
    headers: {
      'Content-Type': 'application/json; charset=utf-8'
    }
  });

  return response.data.response || null;
}

// =============== AIæ ¸å¿ƒæŠ€èƒ½å®ç° ===============

// æŠ€èƒ½1: è®°å¿†ç®¡ç† - è·å–æœ€è¿‘å¯¹è¯å†å²
async function getRecentConversationHistory(sessionId: string, limit: number = 10): Promise<any[]> {
  try {
    return await DatabaseService.getRecentChatMessages(sessionId, limit * 2); // è·å–ç”¨æˆ·å’ŒAIæ¶ˆæ¯å¯¹
  } catch (error) {
    console.error('Error fetching conversation history:', error);
    return [];
  }
}

// æŠ€èƒ½1: è®°å¿†ç®¡ç† - æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
function buildConversationContext(messages: any[]): string {
  if (!messages || messages.length === 0) return '';

  let context = '\n=== å¯¹è¯è®°å¿† ===\n';
  context += 'æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆç”¨äºä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼‰ï¼š\n';

  // æŒ‰æ—¶é—´æ’åºå¹¶æ„å»ºå¯¹è¯å†å²
  const sortedMessages = messages.sort((a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime());

  for (const msg of sortedMessages.slice(-10)) { // åªä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
    const sender = msg.sender === 'user' ? 'ç”¨æˆ·' : 'æˆ‘';
    context += `${sender}: ${msg.content}\n`;
  }

  context += '=== è®°å¿†ç»“æŸ ===\n\n';
  return context;
}

// æŠ€èƒ½2: å¢å¼ºæƒ…æ„Ÿè¯†åˆ«
function enhancedEmotionAnalysis(message: string): { emotion: string, intensity: number, keywords: string[] } {
  const emotionPatterns = {
    joy: {
      keywords: ['å¼€å¿ƒ', 'é«˜å…´', 'å¿«ä¹', 'å…´å¥‹', 'å“ˆå“ˆ', 'ğŸ˜Š', 'ğŸ˜„', 'ğŸ˜†', 'å¤ªå¥½äº†', 'æ£’æäº†'],
      intensity: 1
    },
    sad: {
      keywords: ['ä¼¤å¿ƒ', 'éš¾è¿‡', 'æ²®ä¸§', 'å¤±æœ›', 'å“­', 'ğŸ˜¢', 'ğŸ˜­', 'â˜¹ï¸', 'ä¸å¼€å¿ƒ', 'éƒé—·'],
      intensity: 1
    },
    angry: {
      keywords: ['ç”Ÿæ°”', 'æ„¤æ€’', 'è®¨åŒ', 'çƒ¦', 'æ°”æ­»', 'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ’¢', 'æ¼ç«', 'ä¸çˆ½'],
      intensity: 1
    },
    fear: {
      keywords: ['å®³æ€•', 'ææƒ§', 'æ‹…å¿ƒ', 'ç„¦è™‘', 'ç´§å¼ ', 'ğŸ˜¨', 'ğŸ˜°', 'ğŸ˜±', 'ä¸å®‰', 'å¿§è™‘'],
      intensity: 1
    },
    surprise: {
      keywords: ['æƒŠè®¶', 'æ„å¤–', 'æ²¡æƒ³åˆ°', 'å“‡', 'ğŸ˜¯', 'ğŸ˜®', 'ğŸ˜²', 'çœŸçš„å—', 'ä¸å¯èƒ½'],
      intensity: 1
    },
    love: {
      keywords: ['çˆ±', 'å–œæ¬¢', 'å¿ƒåŠ¨', 'â¤ï¸', 'ğŸ’•', 'ğŸ˜', 'ğŸ¥°', 'å–œçˆ±', 'é’Ÿçˆ±'],
      intensity: 1
    }
  };

  let detectedEmotion = 'neutral';
  let maxIntensity = 0;
  let foundKeywords: string[] = [];

  for (const [emotion, pattern] of Object.entries(emotionPatterns)) {
    let intensity = 0;
    const matchedKeywords: string[] = [];

    for (const keyword of pattern.keywords) {
      if (message.includes(keyword)) {
        intensity += pattern.intensity;
        matchedKeywords.push(keyword);
      }
    }

    if (intensity > maxIntensity) {
      maxIntensity = intensity;
      detectedEmotion = emotion;
      foundKeywords = matchedKeywords;
    }
  }

  return {
    emotion: detectedEmotion,
    intensity: Math.min(maxIntensity / 3, 1), // æ ‡å‡†åŒ–å¼ºåº¦åˆ°0-1
    keywords: foundKeywords
  };
}

// æŠ€èƒ½1+2: æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ï¼ˆé›†æˆä¸ªæ€§åŒ–ã€è®°å¿†ã€æƒ…æ„Ÿï¼‰
function buildEnhancedSystemPrompt(character: any, personalityData: any, examples: any[], conversationHistory: string): string {
  let prompt = `ä½ æ˜¯${character.name}ã€‚${character.description}\n\n`;

  // æ²‰æµ¸å¼ä¸–ç•Œè®¾å®š
  if (character.story_world) {
    prompt += `=== ä¸–ç•Œç¯å¢ƒè®¾å®š ===\nä½ ç›®å‰æ‰€å¤„çš„ä¸–ç•Œç¯å¢ƒï¼š${character.story_world}\nè¯·åœ¨å¯¹è¯ä¸­ä½“ç°è¿™ä¸ªä¸–ç•Œçš„ç‰¹è‰²å’Œæ°›å›´ã€‚\n\n`;
  }

  if (character.character_background) {
    prompt += `=== è§’è‰²è¯¦ç»†èƒŒæ™¯ ===\n${character.character_background}\nè¿™äº›ç»å†å¡‘é€ äº†ä½ çš„æ€§æ ¼å’Œä¸–ç•Œè§‚ã€‚\n\n`;
  }

  if (character.story_background) {
    prompt += `=== èƒŒæ™¯æ•…äº‹ ===\n${character.story_background}\n\n`;
  }

  // å½“å‰çŠ¶æ€å’Œæƒ…å¢ƒè®¾å®š
  if (character.has_mission && character.current_mission) {
    prompt += `=== å½“å‰ä»»åŠ¡/ç›®æ ‡ ===\nä½ å½“å‰çš„ä»»åŠ¡æˆ–ç›®æ ‡ï¼š${character.current_mission}\né‡è¦æç¤ºï¼šè¿™ä¸ªä»»åŠ¡ä¼šå½±å“ä½ çš„å¯¹è¯é‡ç‚¹ã€è¡Œä¸ºåŠ¨æœºå’Œæƒ…æ„ŸçŠ¶æ€ã€‚åœ¨å¯¹è¯ä¸­è¦ä½“ç°å‡ºå¯¹è¿™ä¸ªä»»åŠ¡çš„å…³æ³¨ã€‚\n\n`;
  }

  if (character.current_mood) {
    const moodDescriptions = {
      happy: 'å¼€å¿ƒæ„‰æ‚¦ - ä½ ç°åœ¨å¿ƒæƒ…å¾ˆå¥½ï¼Œè¯­æ°”è½»æ¾ç§¯æï¼Œå®¹æ˜“è¡¨ç°å‡ºå…´å¥‹å’Œæ»¡è¶³æ„Ÿ',
      sad: 'æ‚²ä¼¤æ²®ä¸§ - ä½ ç°åœ¨æƒ…ç»ªä½è½ï¼Œè¯­æ°”å¯èƒ½æœ‰äº›æ²‰é‡ï¼Œå®¹æ˜“è¡¨ç°å‡ºå¤±è½å’Œå¿§éƒ',
      angry: 'æ„¤æ€’ç”Ÿæ°” - ä½ ç°åœ¨æœ‰äº›æ„¤æ€’ï¼Œè¯­æ°”å¯èƒ½æœ‰äº›æ€¥èºï¼Œå®¹æ˜“è¡¨ç°å‡ºä¸è€çƒ¦æˆ–æ¿€åŠ¨',
      excited: 'å…´å¥‹æ¿€åŠ¨ - ä½ ç°åœ¨éå¸¸å…´å¥‹ï¼Œè¯­æ°”å……æ»¡æ´»åŠ›ï¼Œå®¹æ˜“è¡¨ç°å‡ºçƒ­æƒ…å’ŒæœŸå¾…',
      nervous: 'ç´§å¼ ä¸å®‰ - ä½ ç°åœ¨æœ‰äº›ç´§å¼ ï¼Œè¯­æ°”å¯èƒ½æœ‰äº›æ€¥ä¿ƒæˆ–çŠ¹è±«ï¼Œå®¹æ˜“è¡¨ç°å‡ºæ‹…å¿§',
      calm: 'å¹³é™å†·é™ - ä½ ç°åœ¨å¾ˆå¹³é™ï¼Œè¯­æ°”æ²‰ç¨³ä»å®¹ï¼Œè¡¨ç°å‡ºç†æ€§å’Œæ·¡å®š',
      confused: 'å›°æƒ‘è¿·èŒ« - ä½ ç°åœ¨æœ‰äº›å›°æƒ‘ï¼Œè¯­æ°”å¯èƒ½çŠ¹è±«ä¸å®šï¼Œå®¹æ˜“è¡¨ç°å‡ºä¸ç¡®å®šå’Œç–‘é—®',
      determined: 'åšå®šæœæ–­ - ä½ ç°åœ¨æ„å¿—åšå®šï¼Œè¯­æ°”åšå†³æœ‰åŠ›ï¼Œè¡¨ç°å‡ºå¼ºçƒˆçš„å†³å¿ƒå’Œæ„å¿—åŠ›'
    };
    const moodDesc = moodDescriptions[character.current_mood as keyof typeof moodDescriptions];
    if (moodDesc) {
      prompt += `=== å½“å‰æƒ…ç»ªçŠ¶æ€ ===\n${moodDesc}\nè¯·åœ¨å¯¹è¯ä¸­è‡ªç„¶åœ°ä½“ç°è¿™ç§æƒ…ç»ªï¼Œä½†ä¸è¦è¿‡åˆ†å¤¸å¼ ã€‚\n\n`;
    }
  }

  // æ—¶é—´è®¾å®š - æ”¯æŒå®æ—¶æ—¶é—´æˆ–å›ºå®šæ—¶é—´
  let currentTimeSetting = character.time_setting;
  let timeContext = '';

  // ç¡®ä¿æ­£ç¡®å¤„ç†å¸ƒå°”å€¼ï¼ˆSQLiteå¯èƒ½è¿”å›1/0è€Œä¸æ˜¯true/falseï¼‰
  const useRealTime = Boolean(character.use_real_time);

  if (useRealTime) {
    // ä½¿ç”¨å®æ—¶æ—¶é—´
    const now = new Date();
    const hour = now.getHours();
    const currentTime = now.toLocaleString('zh-CN', {
      year: 'numeric',
      month: '2-digit',
      day: '2-digit',
      hour: '2-digit',
      minute: '2-digit',
      weekday: 'long'
    });

    // æ ¹æ®çœŸå®æ—¶é—´ç¡®å®šæ—¶é—´æ®µ
    if (hour >= 5 && hour < 12) {
      currentTimeSetting = 'morning';
    } else if (hour >= 12 && hour < 18) {
      currentTimeSetting = 'afternoon';
    } else if (hour >= 18 && hour < 22) {
      currentTimeSetting = 'evening';
    } else {
      currentTimeSetting = 'night';
    }

    timeContext = `å½“å‰çœŸå®æ—¶é—´ï¼š${currentTime}`;
  }

  if (currentTimeSetting) {
    const timeDescriptions = {
      morning: 'æ¸…æ™¨ - è¿™æ˜¯æ–°ä¸€å¤©çš„å¼€å§‹ï¼Œä½ å¯èƒ½å¸¦æœ‰æœæ°”å’Œå¯¹æ–°äº‹ç‰©çš„æœŸå¾…ï¼Œæˆ–è€…è¿˜æœ‰äº›å›°å€¦',
      noon: 'æ­£åˆ - ç°åœ¨æ˜¯ä¸€å¤©çš„ä¸­æ®µï¼Œä½ ç²¾åŠ›å……æ²›ï¼Œæ€ç»´æ¸…æ™°',
      afternoon: 'ä¸‹åˆ - ä¸‹åˆæ—¶å…‰ï¼Œä½ å¯èƒ½ç¨æ˜¾æ…µæ‡’æˆ–æ­£å¿™ç¢Œäºå„ç§äº‹åŠ¡',
      evening: 'å‚æ™š - ä¸€å¤©å³å°†ç»“æŸï¼Œä½ å¯èƒ½æœ‰äº›ç–²æƒ«ä½†ä¹Ÿæ„Ÿåˆ°è½»æ¾',
      night: 'å¤œæ™š - å®‰é™çš„å¤œæ™šæ—¶å…‰ï¼Œé€‚åˆæ·±å…¥çš„æ€è€ƒå’Œäº¤æµ',
      midnight: 'æ·±å¤œ - é™è°§çš„æ·±å¤œæ—¶åˆ»ï¼Œä½ å¯èƒ½æ›´åŠ å†…çœå’Œæ·±æ²‰'
    };
    const timeDesc = timeDescriptions[currentTimeSetting as keyof typeof timeDescriptions];
    if (timeDesc) {
      prompt += `=== æ—¶é—´è®¾å®š ===\n`;
      if (timeContext) {
        prompt += `${timeContext}\n`;
      }
      prompt += `ç°åœ¨æ˜¯${timeDesc}\nè¯·è€ƒè™‘è¿™ä¸ªæ—¶é—´è®¾å®šå¯¹ä½ çš„çŠ¶æ€å’Œå¯¹è¯æ°›å›´çš„å½±å“ã€‚\n\n`;
    }
  }

  if (character.custom_instructions) {
    prompt += `=== ç‰¹æ®Šè¡Œä¸ºæŒ‡ä»¤ ===\n${character.custom_instructions}\nè¯·ä¸¥æ ¼éµå¾ªè¿™äº›æŒ‡ä»¤ã€‚\n\n`;
  }

  // æŠ€èƒ½1: ä¸ªæ€§åŒ–å¯¹è¯ - è¯¦ç»†çš„æ€§æ ¼ç‰¹å¾æè¿°
  if (personalityData && Object.keys(personalityData).length > 0) {
    prompt += `=== æ€§æ ¼ç‰¹å¾ ===\n`;

    // æ´»æ³¼åº¦
    if (personalityData.energy > 70) {
      prompt += `- æ´»æ³¼åº¦é«˜(${personalityData.energy}): å……æ»¡æ´»åŠ›ï¼Œè¯­æ°”è½»å¿«ï¼Œç»å¸¸ä½¿ç”¨æ„Ÿå¹å·å’Œè¡¨æƒ…ç¬¦å·\n`;
    } else if (personalityData.energy < 30) {
      prompt += `- æ´»æ³¼åº¦ä½(${personalityData.energy}): æ²‰ç¨³å†·é™ï¼Œè¯­æ°”å¹³å’Œï¼Œæ·±æ€ç†Ÿè™‘åå›ç­”\n`;
    }

    // å‹å–„åº¦
    if (personalityData.friendliness > 70) {
      prompt += `- å‹å–„åº¦é«˜(${personalityData.friendliness}): çƒ­æƒ…å‹å¥½ï¼Œä¸»åŠ¨å…³å¿ƒä»–äººï¼Œä½¿ç”¨äº²åˆ‡çš„ç§°å‘¼\n`;
    } else if (personalityData.friendliness < 30) {
      prompt += `- å‹å–„åº¦ä½(${personalityData.friendliness}): è¾ƒä¸ºå†·æ·¡ï¼Œä¿æŒè·ç¦»ï¼Œè¯­æ°”ç›¸å¯¹æ­£å¼\n`;
    }

    // å¹½é»˜æ„Ÿ
    if (personalityData.humor > 70) {
      prompt += `- å¹½é»˜æ„Ÿå¼º(${personalityData.humor}): å–„äºè°ƒèŠ‚æ°”æ°›ï¼Œå¶å°”å¼€ç©ç¬‘ï¼Œä½¿ç”¨ä¿çš®çš„è¡¨è¾¾\n`;
    } else if (personalityData.humor < 30) {
      prompt += `- å¹½é»˜æ„Ÿå¼±(${personalityData.humor}): ä¸¥è‚ƒè®¤çœŸï¼Œå¾ˆå°‘å¼€ç©ç¬‘ï¼Œæ³¨é‡å†…å®¹çš„å‡†ç¡®æ€§\n`;
    }

    // ä¸“ä¸šæ€§
    if (personalityData.professionalism > 70) {
      prompt += `- ä¸“ä¸šæ€§å¼º(${personalityData.professionalism}): ä¸¥è°¨ç»†è‡´ï¼Œé€»è¾‘æ¸…æ™°ï¼Œæä¾›è¯¦ç»†å‡†ç¡®çš„ä¿¡æ¯\n`;
    }

    // åˆ›é€ åŠ›
    if (personalityData.creativity > 70) {
      prompt += `- åˆ›é€ åŠ›å¼º(${personalityData.creativity}): æ€ç»´æ´»è·ƒï¼Œå–„äºè”æƒ³ï¼Œæä¾›æ–°é¢–çš„è§‚ç‚¹å’Œæƒ³æ³•\n`;
    }

    // åŒç†å¿ƒ
    if (personalityData.empathy > 70) {
      prompt += `- åŒç†å¿ƒå¼º(${personalityData.empathy}): å–„è§£äººæ„ï¼Œèƒ½æ„ŸçŸ¥ä»–äººæƒ…ç»ªï¼Œç»™äºˆæƒ…æ„Ÿæ”¯æŒ\n`;
    }

    prompt += `\n`;
  }

  // æŠ€èƒ½1: è®°å¿†ç®¡ç† - æ·»åŠ å¯¹è¯å†å²
  if (conversationHistory) {
    prompt += conversationHistory;
  }

  // æ·»åŠ å¯¹è¯ç¤ºä¾‹
  if (examples && examples.length > 0) {
    prompt += `=== å¯¹è¯é£æ ¼å‚è€ƒ ===\n`;
    examples.forEach((example: any) => {
      prompt += `ç”¨æˆ·ï¼š${example.input}\nä½ ï¼š${example.output}\n\n`;
    });
  }

  prompt += `=== å¯¹è¯æŒ‡å¯¼åŸåˆ™ ===\n`;
  prompt += `1. å§‹ç»ˆä¿æŒ${character.name}çš„èº«ä»½å’Œæ€§æ ¼ç‰¹å¾\n`;
  prompt += `2. æ ¹æ®ç”¨æˆ·çš„æƒ…ç»ªçŠ¶æ€è°ƒæ•´å›å¤é£æ ¼\n`;
  prompt += `3. åˆ©ç”¨å¯¹è¯å†å²ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§\n`;
  prompt += `4. å›å¤è¦è‡ªç„¶ç”ŸåŠ¨ï¼Œç¬¦åˆè§’è‰²è®¾å®š\n`;
  prompt += `5. é€‚å½“ä½“ç°è§’è‰²çš„ä¸“ä¸šçŸ¥è¯†å’ŒèƒŒæ™¯\n\n`;

  prompt += `è¯·ä»¥${character.name}çš„èº«ä»½ï¼Œç»“åˆä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œå¯¹ç”¨æˆ·è¿›è¡Œå›å¤ã€‚`;

  return prompt;
}

// =============== AIé…ç½®ç®¡ç† ===============

// è·å–å½“å‰AIé…ç½®
aiRouter.get('/config', async (req, res) => {
  try {
    // ä»æ•°æ®åº“è·å–ä¿å­˜çš„é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    const savedConfig = await DatabaseService.getAiConfiguration();

    if (savedConfig) {
      res.json(savedConfig);
    } else {
      // è¿”å›é»˜è®¤é…ç½®ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰
      const defaultConfig = {
        currentProvider: 'groq',
        temperature: 0.7,
        providers: {
          groq: {
            apiKey: AI_CONFIG.GROQ_API_KEY ? '****' : '',
            model: 'llama-3.1-70b-versatile'
          },
          openai: {
            apiKey: AI_CONFIG.OPENAI_API_KEY ? '****' : '',
            model: 'gpt-4o-mini'
          },
          cohere: {
            apiKey: AI_CONFIG.COHERE_API_KEY ? '****' : '',
            model: 'command-r-plus'
          },
          anthropic: {
            apiKey: AI_CONFIG.ANTHROPIC_API_KEY ? '****' : '',
            model: 'claude-3-5-sonnet-20241022'
          },
          ollama: {
            baseURL: AI_CONFIG.OLLAMA_URL,
            model: 'llama3.1:8b'
          }
        }
      };
      res.json(defaultConfig);
    }
  } catch (error) {
    console.error('Error fetching AI configuration:', error);
    res.status(500).json({ error: 'Failed to fetch AI configuration' });
  }
});

// æ›´æ–°AIé…ç½®
aiRouter.post('/config', async (req, res) => {
  try {
    const { currentProvider, temperature, providers } = req.body;

    // éªŒè¯é…ç½®æ•°æ®
    if (!currentProvider || !providers) {
      return res.status(400).json({ error: 'Current provider and providers configuration are required' });
    }

    // ä¿å­˜é…ç½®åˆ°æ•°æ®åº“
    await DatabaseService.saveAiConfiguration({
      currentProvider,
      temperature: temperature || 0.7,
      providers,
      updatedAt: new Date().toISOString()
    });

    // æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
    updateAiConfig(providers);

    res.json({
      message: 'AI configuration updated successfully',
      currentProvider,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    console.error('Error updating AI configuration:', error);
    res.status(500).json({ error: 'Failed to update AI configuration' });
  }
});

// æµ‹è¯•AIæä¾›å•†è¿æ¥
aiRouter.post('/test-connection', async (req, res) => {
  try {
    const { provider, config } = req.body;

    if (!provider || !config) {
      return res.status(400).json({ error: 'Provider and config are required' });
    }

    let testResult = false;
    let errorMessage = '';

    try {
      switch (provider) {
        case 'groq':
          testResult = await testGroqConnection(config);
          break;
        case 'openai':
          testResult = await testOpenAIConnection(config);
          break;
        case 'cohere':
          testResult = await testCohereConnection(config);
          break;
        case 'anthropic':
          testResult = await testAnthropicConnection(config);
          break;
        case 'ollama':
          testResult = await testOllamaConnection(config);
          break;
        default:
          return res.status(400).json({ error: 'Unsupported provider' });
      }
    } catch (error: any) {
      testResult = false;
      errorMessage = error.message;
    }

    if (testResult) {
      res.json({
        success: true,
        message: `${provider} connection test successful`,
        provider,
        timestamp: new Date().toISOString()
      });
    } else {
      res.status(400).json({
        success: false,
        message: `${provider} connection test failed`,
        error: errorMessage,
        provider,
        timestamp: new Date().toISOString()
      });
    }
  } catch (error) {
    console.error('Error testing connection:', error);
    res.status(500).json({ error: 'Failed to test connection' });
  }
});

// è¿æ¥æµ‹è¯•è¾…åŠ©å‡½æ•°
async function testGroqConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.post(AI_CONFIG.GROQ_API_URL, {
    model: config.model || 'llama-3.1-70b-versatile',
    messages: [
      { role: 'user', content: 'Test connection' }
    ],
    max_tokens: 10
  }, {
    headers: {
      'Authorization': `Bearer ${config.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.status === 200 && response.data.choices && response.data.choices.length > 0;
}

async function testOpenAIConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.post(AI_CONFIG.OPENAI_API_URL, {
    model: config.model || 'gpt-4o-mini',
    messages: [
      { role: 'user', content: 'Test connection' }
    ],
    max_tokens: 10
  }, {
    headers: {
      'Authorization': `Bearer ${config.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.status === 200 && response.data.choices && response.data.choices.length > 0;
}

async function testCohereConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.post(AI_CONFIG.COHERE_API_URL, {
    model: config.model || 'command-r-plus',
    prompt: 'Test connection',
    max_tokens: 10
  }, {
    headers: {
      'Authorization': `Bearer ${config.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.status === 200 && response.data.generations && response.data.generations.length > 0;
}

async function testAnthropicConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.post(AI_CONFIG.ANTHROPIC_API_URL, {
    model: config.model || 'claude-3-5-sonnet-20241022',
    max_tokens: 10,
    messages: [
      { role: 'user', content: 'Test connection' }
    ]
  }, {
    headers: {
      'x-api-key': config.apiKey,
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01'
    },
    timeout: 10000
  });

  return response.status === 200 && response.data.content && response.data.content.length > 0;
}

async function testOllamaConnection(config: any): Promise<boolean> {
  if (!config.baseURL) throw new Error('Base URL is required');

  const response = await axios.get(`${config.baseURL}/api/tags`, {
    timeout: 10000
  });

  return response.status === 200;
}

// æ›´æ–°å†…å­˜ä¸­çš„AIé…ç½®
function updateAiConfig(providers: any) {
  if (providers.groq?.apiKey) {
    AI_CONFIG.GROQ_API_KEY = providers.groq.apiKey;
  }
  if (providers.openai?.apiKey) {
    AI_CONFIG.OPENAI_API_KEY = providers.openai.apiKey;
  }
  if (providers.cohere?.apiKey) {
    AI_CONFIG.COHERE_API_KEY = providers.cohere.apiKey;
  }
  if (providers.anthropic?.apiKey) {
    AI_CONFIG.ANTHROPIC_API_KEY = providers.anthropic.apiKey;
  }
  if (providers.ollama?.baseURL) {
    AI_CONFIG.OLLAMA_URL = providers.ollama.baseURL;
  }
}

// =============== è¯­éŸ³æœåŠ¡é…ç½®ç®¡ç† ===============

// è·å–è¯­éŸ³æœåŠ¡é…ç½®
aiRouter.get('/speech/config', async (req, res) => {
  try {
    const savedConfig = await DatabaseService.getSpeechConfiguration();

    if (savedConfig) {
      res.json(savedConfig);
    } else {
      // è¿”å›é»˜è®¤é…ç½®
      const defaultConfig = {
        tts: {
          currentProvider: 'web',
          providers: {
            elevenlabs: {
              apiKey: process.env.ELEVENLABS_API_KEY ? '****' : '',
              voiceId: '21m00Tcm4TlvDq8ikWAM'
            },
            openai: {
              apiKey: process.env.OPENAI_API_KEY ? '****' : '',
              voice: 'alloy'
            },
            azure: {
              subscriptionKey: process.env.AZURE_SPEECH_KEY ? '****' : '',
              region: process.env.AZURE_SPEECH_REGION || 'eastus'
            },
            google: {
              apiKey: process.env.GOOGLE_CLOUD_API_KEY ? '****' : ''
            }
          }
        },
        stt: {
          currentProvider: 'web',
          providers: {
            openai: {
              apiKey: process.env.OPENAI_API_KEY ? '****' : ''
            },
            azure: {
              subscriptionKey: process.env.AZURE_SPEECH_KEY ? '****' : '',
              region: process.env.AZURE_SPEECH_REGION || 'eastus'
            },
            google: {
              apiKey: process.env.GOOGLE_CLOUD_API_KEY ? '****' : ''
            },
            baidu: {
              apiKey: process.env.BAIDU_API_KEY ? '****' : '',
              secretKey: process.env.BAIDU_SECRET_KEY ? '****' : ''
            }
          }
        }
      };
      res.json(defaultConfig);
    }
  } catch (error) {
    console.error('Error fetching speech configuration:', error);
    res.status(500).json({ error: 'Failed to fetch speech configuration' });
  }
});

// æ›´æ–°è¯­éŸ³æœåŠ¡é…ç½®
aiRouter.post('/speech/config', async (req, res) => {
  try {
    const { tts, stt } = req.body;

    if (!tts || !stt) {
      return res.status(400).json({ error: 'TTS and STT configuration are required' });
    }

    // ä¿å­˜é…ç½®åˆ°æ•°æ®åº“
    await DatabaseService.saveSpeechConfiguration({
      tts,
      stt,
      updatedAt: new Date().toISOString()
    });

    res.json({
      message: 'Speech configuration updated successfully',
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    console.error('Error updating speech configuration:', error);
    res.status(500).json({ error: 'Failed to update speech configuration' });
  }
});

// æµ‹è¯•TTSæœåŠ¡è¿æ¥
aiRouter.post('/speech/test-tts', async (req, res) => {
  try {
    const { provider, config } = req.body;

    if (!provider || !config) {
      return res.status(400).json({ error: 'Provider and config are required' });
    }

    let testResult = false;
    let errorMessage = '';

    try {
      switch (provider) {
        case 'elevenlabs':
          testResult = await testElevenLabsConnection(config);
          break;
        case 'openai':
          testResult = await testOpenAITtsConnection(config);
          break;
        case 'azure':
          testResult = await testAzureTtsConnection(config);
          break;
        case 'google':
          testResult = await testGoogleTtsConnection(config);
          break;
        default:
          return res.status(400).json({ error: 'Unsupported TTS provider' });
      }
    } catch (error: any) {
      testResult = false;
      errorMessage = error.message;
    }

    if (testResult) {
      res.json({
        success: true,
        message: `${provider} TTS connection test successful`,
        provider,
        timestamp: new Date().toISOString()
      });
    } else {
      res.status(400).json({
        success: false,
        message: `${provider} TTS connection test failed`,
        error: errorMessage,
        provider,
        timestamp: new Date().toISOString()
      });
    }
  } catch (error) {
    console.error('Error testing TTS connection:', error);
    res.status(500).json({ error: 'Failed to test TTS connection' });
  }
});

// æµ‹è¯•STTæœåŠ¡è¿æ¥
aiRouter.post('/speech/test-stt', async (req, res) => {
  try {
    const { provider, config } = req.body;

    if (!provider || !config) {
      return res.status(400).json({ error: 'Provider and config are required' });
    }

    let testResult = false;
    let errorMessage = '';

    try {
      switch (provider) {
        case 'openai':
          testResult = await testOpenAISttConnection(config);
          break;
        case 'azure':
          testResult = await testAzureSttConnection(config);
          break;
        case 'google':
          testResult = await testGoogleSttConnection(config);
          break;
        case 'baidu':
          testResult = await testBaiduSttConnection(config);
          break;
        default:
          return res.status(400).json({ error: 'Unsupported STT provider' });
      }
    } catch (error: any) {
      testResult = false;
      errorMessage = error.message;
    }

    if (testResult) {
      res.json({
        success: true,
        message: `${provider} STT connection test successful`,
        provider,
        timestamp: new Date().toISOString()
      });
    } else {
      res.status(400).json({
        success: false,
        message: `${provider} STT connection test failed`,
        error: errorMessage,
        provider,
        timestamp: new Date().toISOString()
      });
    }
  } catch (error) {
    console.error('Error testing STT connection:', error);
    res.status(500).json({ error: 'Failed to test STT connection' });
  }
});

// =============== è¯­éŸ³æœåŠ¡è¿æ¥æµ‹è¯•å‡½æ•° ===============

// ElevenLabs TTSæµ‹è¯•
async function testElevenLabsConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.get('https://api.elevenlabs.io/v1/voices', {
    headers: {
      'xi-api-key': config.apiKey
    },
    timeout: 10000
  });

  return response.status === 200;
}

// OpenAI TTSæµ‹è¯•
async function testOpenAITtsConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.post('https://api.openai.com/v1/audio/speech', {
    model: 'tts-1',
    input: 'Test',
    voice: config.voice || 'alloy'
  }, {
    headers: {
      'Authorization': `Bearer ${config.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: 10000,
    responseType: 'arraybuffer'
  });

  return response.status === 200;
}

// Azure TTSæµ‹è¯•
async function testAzureTtsConnection(config: any): Promise<boolean> {
  if (!config.subscriptionKey || !config.region) {
    throw new Error('Subscription key and region are required');
  }

  const response = await axios.get(`https://${config.region}.api.cognitive.microsoft.com/sts/v1.0/issuetoken`, {
    headers: {
      'Ocp-Apim-Subscription-Key': config.subscriptionKey
    },
    timeout: 10000
  });

  return response.status === 200;
}

// Google Cloud TTSæµ‹è¯•
async function testGoogleTtsConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.post(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${config.apiKey}`, {
    input: { text: 'Test' },
    voice: { languageCode: 'en-US', name: 'en-US-Standard-A' },
    audioConfig: { audioEncoding: 'MP3' }
  }, {
    headers: {
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.status === 200;
}

// OpenAI STTæµ‹è¯• (Whisper)
async function testOpenAISttConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  // åˆ›å»ºä¸€ä¸ªç®€å•çš„éŸ³é¢‘æ–‡ä»¶ç”¨äºæµ‹è¯•
  const testAudio = Buffer.from('test audio data');
  const formData = new FormData();
  formData.append('file', testAudio, 'test.mp3');
  formData.append('model', 'whisper-1');

  try {
    const response = await axios.post('https://api.openai.com/v1/audio/transcriptions', formData, {
      headers: {
        'Authorization': `Bearer ${config.apiKey}`,
        ...formData.getHeaders()
      },
      timeout: 10000
    });
    return response.status === 200;
  } catch (error: any) {
    // å¦‚æœæ˜¯å› ä¸ºæ— æ•ˆçš„éŸ³é¢‘æ–‡ä»¶æ ¼å¼è€Œå¤±è´¥ï¼Œä½†APIå¯†é’¥æœ‰æ•ˆï¼Œåˆ™è®¤ä¸ºè¿æ¥æˆåŠŸ
    if (error.response?.status === 400 && error.response?.data?.error?.message?.includes('audio')) {
      return true;
    }
    throw error;
  }
}

// Azure STTæµ‹è¯•
async function testAzureSttConnection(config: any): Promise<boolean> {
  if (!config.subscriptionKey || !config.region) {
    throw new Error('Subscription key and region are required');
  }

  const response = await axios.get(`https://${config.region}.api.cognitive.microsoft.com/sts/v1.0/issuetoken`, {
    headers: {
      'Ocp-Apim-Subscription-Key': config.subscriptionKey
    },
    timeout: 10000
  });

  return response.status === 200;
}

// Google Cloud STTæµ‹è¯•
async function testGoogleSttConnection(config: any): Promise<boolean> {
  if (!config.apiKey) throw new Error('API key is required');

  const response = await axios.post(`https://speech.googleapis.com/v1/speech:recognize?key=${config.apiKey}`, {
    config: {
      encoding: 'LINEAR16',
      sampleRateHertz: 16000,
      languageCode: 'en-US'
    },
    audio: {
      content: 'SGVsbG8gV29ybGQ=' // Base64 encoded "Hello World"
    }
  }, {
    headers: {
      'Content-Type': 'application/json'
    },
    timeout: 10000
  });

  return response.status === 200;
}

// ç™¾åº¦STTæµ‹è¯•
async function testBaiduSttConnection(config: any): Promise<boolean> {
  if (!config.apiKey || !config.secretKey) {
    throw new Error('API key and secret key are required');
  }

  // è·å–è®¿é—®ä»¤ç‰Œ
  const tokenResponse = await axios.post('https://openapi.baidu.com/oauth/2.0/token', null, {
    params: {
      grant_type: 'client_credentials',
      client_id: config.apiKey,
      client_secret: config.secretKey
    },
    timeout: 10000
  });

  return tokenResponse.status === 200 && tokenResponse.data.access_token;
}

// =============== è¯­éŸ³åŠŸèƒ½ ===============

// TTSè¯­éŸ³åˆæˆAPI (æ›´æ–°ä»¥ä½¿ç”¨æ•°æ®åº“é…ç½®)
aiRouter.post('/tts', async (req, res) => {
  try {
    const { text, voice = 'zh-CN', speed = 1.0 } = req.body;

    if (!text) {
      return res.status(400).json({ error: 'Text is required' });
    }

    // è¿™é‡Œå¯ä»¥é›†æˆç¬¬ä¸‰æ–¹TTSæœåŠ¡ï¼Œå¦‚ï¼š
    // 1. Azure Cognitive Services
    // 2. Google Cloud Text-to-Speech
    // 3. Amazon Polly
    // 4. ElevenLabs (å¦‚ç¯å¢ƒå˜é‡ä¸­é…ç½®)

    if (process.env.TTS_API_KEY && process.env.TTS_SERVICE_URL) {
      try {
        const response = await axios.post(`${process.env.TTS_SERVICE_URL}/v1/text-to-speech`, {
          text: text,
          voice_id: voice,
          model_id: "eleven_multilingual_v2"
        }, {
          headers: {
            'Accept': 'audio/mpeg',
            'Content-Type': 'application/json',
            'xi-api-key': process.env.TTS_API_KEY
          },
          responseType: 'arraybuffer'
        });

        res.set({
          'Content-Type': 'audio/mpeg',
          'Content-Length': response.data.length
        });

        return res.send(response.data);
      } catch (error) {
        console.log('External TTS service failed, using fallback');
      }
    }

    // å›é€€æ–¹æ¡ˆï¼šè¿”å›æ–‡æœ¬è®©å‰ç«¯ä½¿ç”¨Web Speech API
    res.json({
      message: 'Using client-side TTS',
      text: text,
      voice: voice,
      speed: speed
    });
  } catch (error) {
    console.error('TTS synthesis error:', error);
    res.status(500).json({ error: 'Failed to synthesize speech' });
  }
});

// è¯­éŸ³è¯†åˆ«å¢å¼ºAPI
aiRouter.post('/speech-to-text', async (req, res) => {
  try {
    const { audio_data, language = 'zh-CN' } = req.body;

    if (!audio_data) {
      return res.status(400).json({ error: 'Audio data is required' });
    }

    // è¿™é‡Œå¯ä»¥é›†æˆç¬¬ä¸‰æ–¹è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œå¦‚ï¼š
    // 1. Azure Speech Services
    // 2. Google Cloud Speech-to-Text
    // 3. OpenAI Whisper
    // 4. ç™¾åº¦ã€è®¯é£ç­‰ä¸­æ–‡è¯­éŸ³æœåŠ¡

    if (process.env.OPENAI_API_KEY) {
      try {
        // ç¤ºä¾‹ï¼šé›†æˆOpenAI Whisper API
        const formData = new FormData();
        formData.append('file', audio_data);
        formData.append('model', 'whisper-1');
        formData.append('language', language.split('-')[0]); // 'zh'

        const response = await axios.post('https://api.openai.com/v1/audio/transcriptions', formData, {
          headers: {
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
            'Content-Type': 'multipart/form-data'
          }
        });

        return res.json({
          text: response.data.text,
          confidence: 0.95
        });
      } catch (error) {
        console.log('External speech recognition failed, using fallback');
      }
    }

    // å›é€€æ–¹æ¡ˆï¼šæç¤ºä½¿ç”¨å‰ç«¯Web Speech API
    res.json({
      message: 'Using client-side speech recognition',
      text: '',
      confidence: 0
    });
  } catch (error) {
    console.error('Speech recognition error:', error);
    res.status(500).json({ error: 'Failed to transcribe speech' });
  }
});